{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles with Randomization, Bagging and Boosting\n",
    "This program generates the random forest with three different methods (randomization, baggaing and boosting) and finally implement the ensembles to classify the gamma ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for decision tree node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeNode(object):\n",
    "    # Constructor\n",
    "    def __init__(self, att, thr, left, right):  \n",
    "        self.attribute = att\n",
    "        self.threshold = thr\n",
    "        # left and right are either binary classifications or references to \n",
    "        # decision tree nodes\n",
    "        self.left = left     \n",
    "        self.right = right   \n",
    "\n",
    "    def print_tree(self,indent=''):\n",
    "        if self.left  in [0,1]:\n",
    "            print(indent+'       ','class=',self.left)\n",
    "        else:\n",
    "            self.left.print_tree(indent+'    ')\n",
    "        print(indent,'if x['+str(self.attribute)+'] <=',self.threshold)\n",
    "        if self.right  in [0,1]:\n",
    "            print(indent+'       ','class=',self.right)\n",
    "        else:\n",
    "            self.right.print_tree(indent+'    ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(object):\n",
    "    # constructor\n",
    "    def __init__(self, max_depth=10, min_samples_split=10, accuracy=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.accuracy = accuracy\n",
    "        \n",
    "    def fit(self, data, labels):\n",
    "        self.root = self._build_tree(data, labels, depth=0)\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        pred = np.zeros(len(test_data), dtype=int)\n",
    "        for i in range(len(test_data)):\n",
    "            pred[i] = self._predict_example(test_data[i], self.root)\n",
    "        return pred\n",
    "        \n",
    "    def _build_tree(self, data, labels, depth):\n",
    "        # check the base case (termination condition)\n",
    "        mean_val = np.mean(labels)\n",
    "        if depth==self.max_depth or len(data)<= self.min_samples_split or max(\n",
    "                [mean_val, 1-mean_val])>= self.accuracy:\n",
    "            return int(round(mean_val))\n",
    "        else:\n",
    "            depth += 1\n",
    "            all_thrs = self._get_all_thrs(data) \n",
    "            # get the best attribute and threshold wth the highest gain\n",
    "            best_split_col, best_split_val = self._get_best_split(data, labels, \n",
    "                                                                  all_thrs)\n",
    "            less, more = self._split_data(data, best_split_col, best_split_val)\n",
    "            #recursivly build the tree\n",
    "            left = self._build_tree(data[less], labels[less], depth)\n",
    "            right = self._build_tree(data[more], labels[more], depth)\n",
    "            \n",
    "\n",
    "        return DecisionTreeNode(best_split_col, best_split_val, left, right)\n",
    "    \n",
    "    def _get_all_thrs(self, data):\n",
    "        all_thrs = {}\n",
    "        for index in range(data.shape[1]):\n",
    "            all_thrs[index] = []\n",
    "            unique_val = np.unique(data[:,index])\n",
    "            \n",
    "            for idx in range(len(unique_val)):\n",
    "                if idx != 0:\n",
    "                    current_val = unique_val[idx]\n",
    "                    previous_val = unique_val[idx - 1]\n",
    "                    thr = (current_val + previous_val)/2\n",
    "                    all_thrs[index].append(thr)\n",
    "        return all_thrs\n",
    "        \n",
    "    # Find the best cloumn to classify and the best threshold value\n",
    "    def _get_best_split(self, data, labels, all_thrs):\n",
    "        best_entropy = 999\n",
    "        for col_index in range(data.shape[1]):\n",
    "            for thr in all_thrs[col_index]: \n",
    "                less, more = self._split_data(data, col_index, thr)\n",
    "                ent = self._entropy(labels[less], labels[more])\n",
    "                \n",
    "                if ent < best_entropy:\n",
    "                    best_entropy = ent\n",
    "                    best_split_col = col_index\n",
    "                    best_split_val = thr\n",
    "        return best_split_col, best_split_val\n",
    "    \n",
    "    def _split_data(self, data, split_col, thr):\n",
    "        less = data[:,split_col] <= thr\n",
    "        more = data[:, split_col] > thr\n",
    "        return less, more\n",
    "\n",
    "    # calculate entropy\n",
    "    def _entropy(self, l, m):\n",
    "        ent = 0\n",
    "        for p in [l, m]:\n",
    "            if len(p) > 0:\n",
    "                pp = sum(p)/len(p)\n",
    "                pn = 1 - pp\n",
    "                if pp < 1 and pp > 0:\n",
    "                    ent -= len(p)*(pp*np.log2(pp) + pn*np.log2(pn))\n",
    "        ent = ent / (len(l) + len(m))\n",
    "        return ent\n",
    "        \n",
    "    def _predict_example(self, example, tree):\n",
    "        col_id = tree.attribute\n",
    "        val = tree.threshold\n",
    "    \n",
    "        if example[col_id] <= val:\n",
    "            answer = tree.left\n",
    "        else:\n",
    "            answer = tree.right\n",
    "            \n",
    "        if not isinstance(answer, DecisionTreeNode):\n",
    "            return answer\n",
    "        else:\n",
    "            remaining_tree = answer\n",
    "            return self._predict_example(example, remaining_tree)\n",
    "     \n",
    "    def display(self):\n",
    "        print(\"model\")\n",
    "        self.root.print_tree()\n",
    "        \n",
    "    def confusion_matrix(self, pred, labels):\n",
    "        cm = np.zeros((np.max(pred)+1, np.max(pred)+1))\n",
    "        for i in range(len(pred)):\n",
    "            cm[pred[i]][labels[i]] += 1\n",
    "        return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load gamma ray dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gamma_ray(standarize=True):\n",
    "    # load and prepare data\n",
    "    x = []\n",
    "    y = []\n",
    "    infile = open(\"gamma_ray.txt\",\"r\")\n",
    "    for line in infile:\n",
    "        y.append(int(line[-2:-1] =='g'))\n",
    "        x.append(np.fromstring(line[:-2], dtype=float,sep=','))\n",
    "    infile.close()\n",
    "        \n",
    "    x = np.array(x).astype(np.float32)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    #Split data into training and testing\n",
    "    ind = np.random.permutation(len(y))\n",
    "    split_ind = int(len(y)*0.8)\n",
    "    x_train = x[ind[:split_ind]]\n",
    "    x_test = x[ind[split_ind:]]\n",
    "    y_train = y[ind[:split_ind]]\n",
    "    y_test = y[ind[split_ind:]]    \n",
    "    \n",
    "    skip = 2   \n",
    "    x_train = x_train[::skip]\n",
    "    y_train = y_train[::skip]\n",
    "    x_test = x_test[::skip]\n",
    "    y_test = y_test[::skip]\n",
    "    \n",
    "    if standarize:\n",
    "        s = np.std(x_train, axis = 0)\n",
    "        mu = np.mean(x_train, axis = 0)\n",
    "        x_train = (x_train - s)/mu\n",
    "        \n",
    "        s = np.std(x_test, axis = 0)\n",
    "        mu = np.mean(x_test, axis = 0)\n",
    "        x_test = (x_test - s)/mu\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset selection based on prbability distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the probability distribution and number of elements, this fuction returnt the index of the selected entities based on\n",
    "#the given probility distribution\n",
    "def prob_select(prob, n):\n",
    "    cs = np.cumsum(prob)\n",
    "    R = np.sort(np.random.rand(n))\n",
    "    S = []\n",
    "    i = 0\n",
    "    for r in R:\n",
    "        while r > cs[i]:\n",
    "            i += 1\n",
    "        S.append(i)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update probabilty distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the wrong prediction entity index and the previous probability distribution, this fuction returns the updated \n",
    "#probability distributin. The probaility is increased by 50% for which the prediction is wrong\n",
    "def update_prob(wrong_idx, p):\n",
    "    for i in range(len(wrong_idx)):\n",
    "        if wrong_idx[i] == True:\n",
    "            p[i] = p[i]*1.5 #probability is increased by 50%\n",
    "    return p/np.sum(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indentify the maximum voting for ensembles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the predictions from all the individaul ensemble, it return the maximum voting for each entities\n",
    "def max_vote(pred):\n",
    "    pred = np.array(pred).T\n",
    "    ens_pred = []\n",
    "    for i in range(len(pred)):\n",
    "        freq = np.array(np.unique(pred[i,:], return_counts=True)).T\n",
    "        idx = np.argmax(freq[:,1])\n",
    "        p = freq[idx,0]\n",
    "        ens_pred.append(p)\n",
    "    return ens_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest ensembles with three methods:\n",
    "        1. Randomization\n",
    "        2. Bagging\n",
    "        3. Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest(x_train, y_train, x_test, y_test, trees=5, max_depth=10, ensemble=\"boosting\"):\n",
    "    if ensemble == \"boosting\":\n",
    "        print(\"Randomforest with boosting....\")\n",
    "        prob = [1/len(x_train)]*len(x_train)\n",
    "        pred = []\n",
    "        for tree in range(trees):\n",
    "            prob_idx = prob_select(prob, int(len(x_train)*0.8))\n",
    "            p_x_train = x_train[prob_idx,:]\n",
    "            p_y_train = y_train[prob_idx]\n",
    "            \n",
    "            model = DecisionTreeClassifier(max_depth=max_depth)\n",
    "            model.fit(p_x_train, p_y_train)\n",
    "            \n",
    "            train_pred = model.predict(x_train)\n",
    "            train_acc = np.mean(train_pred == y_train)\n",
    "            \n",
    "            test_pred = model.predict(x_test)\n",
    "            test_acc = np.mean(test_pred == y_test)\n",
    "            \n",
    "            print(\"Tree:{}/{}  Train accuracy: {}  Test accuracy: {}\".format(tree+1, trees, train_acc, test_acc))\n",
    "            \n",
    "            wrong_idx = train_pred != y_train\n",
    "            prob = update_prob(wrong_idx, prob)\n",
    "            \n",
    "            pred.append(test_pred)\n",
    "        return pred\n",
    "    \n",
    "    if ensemble==\"bagging\":\n",
    "        print(\"Randomforest with bagging....\")\n",
    "        pred = []\n",
    "        for tree in range(trees):\n",
    "            idx = np.random.randint(len(x_train), size=int(len(x_train)*0.8))\n",
    "            b_x_train = x_train[idx,:]\n",
    "            b_y_train = y_train[idx]\n",
    "            \n",
    "            model = DecisionTreeClassifier(max_depth=max_depth)\n",
    "            model.fit(b_x_train, b_y_train)\n",
    "            \n",
    "            train_pred = model.predict(x_train)\n",
    "            train_acc = np.mean(train_pred == y_train)\n",
    "            \n",
    "            test_pred = model.predict(x_test)\n",
    "            test_acc = np.mean(test_pred == y_test)\n",
    "            \n",
    "            print(\"Tree:{}/{}  Train accuracy: {}  Test accuracy: {}\".format(tree+1, trees, train_acc, test_acc))\n",
    "            \n",
    "            pred.append(test_pred)\n",
    "        return pred\n",
    "    \n",
    "    if ensemble==\"randomization\":\n",
    "        print(\"Randomforest with randomization....\")\n",
    "        pred = []\n",
    "        for tree in range(trees):\n",
    "            idx = np.random.permutation(len(x_train))\n",
    "            r_x_train = x_train[idx[:int(len(x_train)*0.8)]]\n",
    "            r_y_train = y_train[idx[:int(len(x_train)*0.8)]]\n",
    "    \n",
    "            model = DecisionTreeClassifier(max_depth=max_depth)\n",
    "            model.fit(r_x_train, r_y_train)\n",
    "            \n",
    "            train_pred = model.predict(x_train)\n",
    "            train_acc = np.mean(train_pred == y_train)\n",
    "            \n",
    "            test_pred = model.predict(x_test)\n",
    "            test_acc = np.mean(test_pred == y_test)\n",
    "            \n",
    "            print(\"Tree:{}/{}  Train accuracy: {}  Test accuracy: {}\".format(tree+1, trees, train_acc, test_acc))\n",
    "            \n",
    "            pred.append(test_pred)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomforest with boosting....\n",
      "Tree:1/5  Train accuracy: 0.8349106203995794  Test accuracy: 0.8165089379600421\n",
      "Tree:2/5  Train accuracy: 0.8378023133543638  Test accuracy: 0.8070452155625657\n",
      "Tree:3/5  Train accuracy: 0.8169032597266036  Test accuracy: 0.8054679284963197\n",
      "Tree:4/5  Train accuracy: 0.8103312302839116  Test accuracy: 0.7781282860147214\n",
      "Tree:5/5  Train accuracy: 0.7748422712933754  Test accuracy: 0.7618296529968455\n",
      "Ensemble time: 336.585867 sec\n",
      "Ensemble test accuracy: 0.841745531019979\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load_gamma_ray()\n",
    "\n",
    "method = \"boosting\" #change to others method \"randomization\" and \"bagging\"\n",
    "max_depth = 5 #change to other numbers, if you want\n",
    "trees = 5 #change to other numbers, if you want\n",
    "\n",
    "start = time.time()\n",
    "pred = randomforest(x_train, y_train, x_test, y_test, trees=trees, max_depth=max_depth, ensemble=method)\n",
    "elapsed_time = time.time() - start\n",
    "print(\"Ensemble time: {0:.6f} sec\".format(elapsed_time))\n",
    "\n",
    "ens_pred = max_vote(pred)\n",
    "accuracy = np.mean(ens_pred == y_test)\n",
    "print(\"Ensemble test accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
